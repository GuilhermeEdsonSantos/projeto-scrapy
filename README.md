# ğŸ“š Web Scraper â€“ GoodReads

Este projeto Ã© um scraper desenvolvido com **Python** e **Scrapy** que coleta citaÃ§Ãµes, autores e tags do site [GoodReads](https://www.goodreads.com/quotes). Ele realiza a navegaÃ§Ã£o automÃ¡tica por todas as pÃ¡ginas do site, trata os dados coletados e exporta os resultados em formato `.csv`.

# ğŸ” Funcionalidades

- ExtraÃ§Ã£o de citaÃ§Ãµes de todas as pÃ¡ginas
- Captura do nome do autor e das tags associadas a cada frase
- Tratamento e limpeza de dados textuais
- PaginaÃ§Ã£o automÃ¡tica (navegaÃ§Ã£o entre pÃ¡ginas)
- ExportaÃ§Ã£o dos dados para CSV

## ğŸ› ï¸ Tecnologias utilizadas

- Python 3
- Scrapy
- XPath
- ManipulaÃ§Ã£o de texto em Python
- ExportaÃ§Ã£o em CSV

## ğŸš€ Como executar o projeto

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/seu-usuario/nome-do-repo.git
   cd nome-do-repo

2.Crie e ative um ambiente virtual (opcional, mas recomendado):

bash

python -m venv venv

venv\Scripts\activate  # Windows

source venv/bin/activate   # Linux/macOS

3.Instale o Scrapy:
bash
pip install scrapy

ğŸ“Œ ObservaÃ§Ãµes
O projeto foi criado para fins educacionais, com foco em aprendizado prÃ¡tico de web scraping com Scrapy.
O GoodReads possui termos de uso, e esse scraper deve ser utilizado com responsabilidade, apenas para fins de estudo.

ğŸ“ Resultado
O resultado serÃ¡ salvo como citacoes.csv, contendo as colunas: frase, autor e tags.
